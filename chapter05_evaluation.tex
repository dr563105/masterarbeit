\chapter{Evaluation}
In this chapter, the workflow explained in last chapter is evaluated and results are
presented.

Before showing the evaluation, it is necessary to define training and testing conditions
that can be easily used by others to verify the results.
\begin{figure}[h]
    \centering
    \def\svgwidth{0.3\textwidth}
    \input{figures/inkscape/datasets_general.pdf_tex}
    \caption{Datasets distribution}
    \label{fig:datasetsdistribution}
\end{figure}

We have three datasets that can be used for training and evaluation.
\begin{enumerate}
    \item Dataset 1 - Contains 100,000 raw data as seen in figure
        \ref{fig:datasetsdistribution}. It is collected in no traffic
        environment, doing straight driving without any sudden turning. The data is using
        San Francisco map and driven during afternoon. This dataset has only data
        representing centre camera pointed ahead, parallel to the ground and right camera
        pointed to the ground at an angle $20^{\circ}$. The control commands include
        acceleration, throttle, braking, and steering angle values.
    \item Dataset 2 - Also contains 100,000 raw data. It is, however, collected with traffic
        where the cars stop at signal intersections for a longer time than dataset 3. This
        dataset is also collect in San Francisco map and during afternoon. It contains a
        centre camera, right camera like dataset 1, left camera similar to right camera by
        pointing at an angle $20^{\circ}$ to the ground, depth camera sensors placed at
        centre, left and right just like RGB cameras. The control commands are same as
        dataset 1.
    \item Dataset 3 - Contains 270,000 raw data. It is collected while driving around San
        Francisco. About 200,000 data is collected while driving in the afternoon. About
        20,000 in different weather and light conditions. About 50,000 entries are
        collected in a different circular circuit map called CubeTown. In addition to RGB
        and depth cameras distributed just as dataset 2, a segmentation camera is kept
        next to centre RGB camera facing forward, and a radar sensor just in front of the
        car near the hood also facing forward.

\end{enumerate}

\section*{Evaluation setup}
While evaluating, a testing parameter \textit{episode} is used. Each episode lasts 30 seconds. A timer is started for 30 seconds and
the  model is tested for collisions. If a collision happens, the time at which collision
happened is noted.

As supervised learning is used, the models have to be tested/validated with unknown data
to determine its capability. Hence the datasets are split 80-20. Meaning 80\% is train
data and 20\% validation data. The optimizer \textit{Adam} takes the 20\% data to test the
trained model. Training data leads to training loss and test data to validation loss.

Also till a single dataset is chosen, all datasets are of equal data entries.

\section{Determine which datasets and best lighting conditions to test the model}
\label{chapter05subsec:setup1}
All three datasets are used. The test is conducted in San Francisco map without traffic
option switched ON. By varying the light conditions to morning, afternoon and evening, we
observe how light influences the prediction of output(see table \ref{table:timeoftheday}).

The steering angle is a continuous value ranging between -1 and 1(negative values to
turn left and positive values to turn right), a continuous loss function has to be used.
Because of that \textit{mean square error}(MSE) as loss function is chosen.
Only steering angle is predicted
and a steady velocity of 3 meter per second is used. An episode length of 30s is used.
When a collision is observed, the time of collision and the number of collisions are noted down.
\begin{table}[t]
    \centering
\begin{tabular}{cccc}
    \toprule
    time(in 24 hrs standard) & Morning & Afternoon & Evening \\\midrule
      & 7:30 & 15:30 & 18:30 \\\bottomrule
\end{tabular}
\caption{Time of the day}
\label{table:timeoftheday}
\end{table}

\begin{figure}[h]
	\centering
    \def\svgwidth{0.9\textwidth}
    \input{figures/inkscape/lightvscollisionvstraffic.pdf_tex} %use full path to know the location of pdftex
    \caption{a) Datasets vs Light Conditions vs Collisions.
        b) Afternoon - Datasets vs Traffic vs Number of Collisions.
    c) Average number of collisions in percentage}
    \label{fig:dsvslcvstrafficAll}
\end{figure}

It is seen from figure \ref{fig:dsvslcvstrafficAll}(a) that afternoon time provides the best light conditions for all the three
datasets. Dataset 1 and 3 perform equally across the three lighting conditions.

If the percentage of number of collisions with traffic toggled ON, as shown in figure
\ref{fig:dsvslcvstrafficAll}(c), is calculated, dataset 3 performs the best among
the datasets for morning and afternoon part of the day.

\subsection{Datasets performance during afternoon if traffic is enabled}
All three datasets are again used. The time is fixed at 15:30. The traffic is toggled ON.
From figure \ref{fig:dsvslcvstrafficAll}(b), we can observe that all three datasets do
well even in traffic. However, it is surprising to see dataset 1 which had no traffic
while the dataset was collected, performs remarkably well when driven in traffic.
\subsection{Observations}
\begin{enumerate}
    \item All 3 datasets do well at afternoon time of the day.
    \item Predicting only steering angle with MSE as loss function works as seen from
        \ref{fig:dsvslcvstrafficAll}.
    \item Dataset 2 shows higher number of collisions. So it is better to avoid for
        further analysis.
\end{enumerate}

\section{Acceleration - Determine which activation and loss functions to use}

\subsection{Tanh as activation and MSE as loss functions}
Since acceleration and steering values in LGSVL range from \textit{-1} to \textit{1},
\textit{tanh} activation function is selected as the output dense layer activation
function.

A set of criteria are listed and the trained model is evaluated based on these conditions.
From table \ref{table:tanhmse} it can be observed that dataset 1 outperforms dataset 3 in
most of the conditions. Dataset 1 retains good steering control at high speeds and
turning, but acceleration skews steering angle when traffic is switched ON. Dataset 3 when
evaluated stops completely after moving a few metres. This causes difficulty in evaluating
according to the criteria. Hence it is assumed that this dataset fails to meet the
criteria.

One of the reasons as to why dataset 3 fails could be because the losses are much higher
than dataset 1 and the validation loss starts to overfit too quickly in the training(see
figure \ref{fig:ds1andd3tanhactivatonMSE}).
\begin{table}[h]
    \centering
\begin{tabular}{lcc}
    \toprule
    Criteria(Tanh/MSE) & Dataset 1 & Dataset 3 \\\midrule
    Lane keeping/Drive straight  & Yes & No  \\
    Gradual acceleration increase & Yes & No\\
    Smooth braking behaviour observed & Yes & No \\
    Smooth steering control at high speed(10m/s) & Yes & No \\
    Smooth steering control at turnings & Yes & No\\
    Detects traffic as dynamic objects & Yes & No\\
    Navigates traffic smoothly & No & No\\
    Doesn't stop at random places & No & No \\\bottomrule
\end{tabular}
\caption{Tanh/MSE - How the model evaluates to different criteria}
\label{table:tanhmse}
\end{table}
\begin{figure}[h]
	\centering
    \def\svgwidth{\textwidth}
    \input{figures/inkscape/regressionModelsTanhActivation.pdf_tex} %use full path to know the location of pdftex
    \caption{Datasets 1 vs 3 - Acceleration and Steering using Tanh activation and MSE loss
    functions.}
    \label{fig:ds1andd3tanhactivatonMSE}
\end{figure}

\subsection{Sigmoid as activation and MSE as loss functions}
The acceleration values are split into positive and negative values. Instead of negative
values an another variable we will call as \textit{braking} is introduced. Negative
acceleration values mean braking is active. Using this knowledge, sigmoid as activation function and mean
square error as loss function, a training is conducted for both datasets 1 and 3.

Criteria similar to table \ref{table:tanhmse} are put to test with this activation and
loss function. As seen in table \ref{table:sigmse}, both datasets fail to meet the
conditions. During evaluation, both datasets trained models, accelerate to a huge velocity
such as 40m/s and the steering cannot keep up, resulting in collisions.

Looking into their losses (see figure \ref{fig:ds1andd3SigactivatonMSE}), don't really
explain much. Though this needs more investigation, for now we assume this activation or
loss function is not suitable.
\ref{fig:ds1andd3tanhactivatonMSE}.
\begin{table}[h]
    \centering
\begin{tabular}{lcc}
    \toprule
    Criteria(Sigmoid/MSE) & Dataset 1 & Dataset 3 \\\midrule
    Lane keeping/Drive straight  & No & No  \\
    Gradual acceleration increase & No & No\\
    Smooth braking behaviour observed & No & No \\
    Smooth steering control at high speed(10m/s) & No & No \\
    Smooth steering control at turnings & No & No\\
    Detects traffic as dynamic objects & No & No\\
    Navigates traffic smoothly & No & No\\
    Doesn't stop at random places & No & No \\\bottomrule
\end{tabular}
\caption{Sigmoid/MSE - How the model evaluates to different criteria}
\label{table:sigmse}
\end{table}

\begin{figure}[h]
	\centering
    \def\svgwidth{\textwidth}
    \input{figures/inkscape/regressionModelsSigActivation.pdf_tex}
    \caption{Datasets 1 vs 3 - Acceleration and Steering using Sigmoid activation and MSE loss
    functions.}
    \label{fig:ds1andd3SigactivatonMSE}
\end{figure}

\subsection{Softmax as activation and Binary crossentropy as loss functions}
Both tanh and sigmoid activation functions couldn't give stable results to continue
pursuing with those parameters. Hence it is necessary to consider other functions which
may suit our needs.

Since acceleration are basically two discrete values, it would be worthy to try the
training as classification task. The goal of a classification task model is to classify to
which category the prediction belongs to. In our case, acceleration or braking. Hence
\textit{softmax} activation function is needed. As loss function \textit{binary
crossentropy} is used to classify as binary classes. Of course for steering angle,
being continuous, MSE is preferred.

From table \ref{table:softmaxandbce}, both datasets don't do well. Dataset 1 doesn't start
at all as braking class dominates the evaluation whereas dataset 3 starts to move the car
but resorts to brake indefinitely after a few metres of driving. This behaviour
necessitates further analysis into the datasets.
\begin{table}[h]
    \centering
\begin{tabular}{lcc}
    \toprule
    Criteria(Softmax/Binary crossentropy) & Dataset 1 & Dataset 3 \\\midrule
    Lane keeping/Drive straight  & No & Yes  \\
    Gradual acceleration increase & No & No\\
    Smooth braking behaviour observed & No & No \\
    Smooth steering control at high speed(10m/s) & No & No \\
    Smooth steering control at turnings & No & No\\
    Detects traffic as dynamic objects & No & No\\
    Navigates traffic smoothly & No & No\\
    Doesn't stop at random places & No & No \\\bottomrule
\end{tabular}
\caption{Softmax/Binary crossentropy - How the model evaluates to different criteria}
\label{table:softmaxandbce}
\end{table}
\iffalse
\begin{figure}[h]
	\centering
    \def\svgwidth{0.8\textwidth}
    \input{figures/inkscape/BinaryCross2.pdf_tex} %use full path to know the location of pdftex
    \caption{Dataset 1 - Binary Crossentropy}
    \label{fig:ds1binarycrossentropy}
\end{figure}

\begin{figure}[h]
	\centering
    \def\svgwidth{0.8\textwidth}
    \input{figures/inkscape/BinaryCross2ds3.pdf_tex} %use full path to know the location of pdftex
    \caption{Dataset 3 - Binary Crossentropy}
    \label{fig:ds3binarycrossentropy}
\end{figure}
\fi
\subsection*{Control commands distribution}
When the datasets are analysed for patterns of different states -- acceleration and
braking, distribution chart(figure \ref{fig:datasetscomparectrlcmds}) reveals that in addition to
acceleration and braking states, there is a third state called \textit{no action} where
the vehicle does absolutely nothing. In fact this state dominates in both datasets.
Because of this, the binary crossentropy obviously fails to meet the conditions.
\begin{figure}[!ht]
    \centering
    \def\svgwidth{\textwidth}
    \input{figures/inkscape/datasets_control_cmds.pdf_tex}
    \caption{Datasets 1 vs 3 control commands distribution}
    \label{fig:datasetscomparectrlcmds}
\end{figure}

\subsection{Softmax as activation and Categorical crossentropy loss functions}
So now we know that this dominant state \textit{no action} needs a separate label if
classification task has to be continued. After creating the label, we would then have
three labels -- acceleration, braking and no action. Hence, we use a new classification
loss function called \textit{categorical crossentropy}. This loss function classifies
model into each category.

\begin{table}[h]
    \centering
\begin{tabular}{lcc}
    \toprule
    Criteria(Softmax/Categorical crossentropy) & Dataset 1 & Dataset 3 \\\midrule
    Lane keeping/Drive straight  & No & Yes  \\
    Gradual acceleration increase & Yes & Yes\\
    Smooth braking behaviour observed & No & Yes \\
    Smooth steering control at high speed(10m/s) & No & No \\
    Smooth steering control at turnings & No & No\\
    Avoids colliding into static objects & No & No \\
    Detects traffic as dynamic objects & Yes & Yes\\
    Navigates traffic smoothly & No & No\\
    Doesn't stop at random places & No & No \\\bottomrule
\end{tabular}
\caption{Softmax/Categorical crossentropy - How the model evaluates to different criteria}
\label{table:softmaxandcce}
\end{table}

From table \ref{table:softmaxandcce}, dataset 1 fails in most conditions and dataset 3
though performs well in 4 out of 9 conditions, shows bad steering behaviour at traffic or high
speeds. If the acceleration is controlled manually, the model reacts better and adapts
itself.

Since no action state dominates, it is necessary to continue as a classification task.
Also dataset 1 has only a small portion for acceleration and even smaller for
braking. Accordingly, dataset 3 is collected with an attempt to increase acceleration
and braking values share. However, since the vehicle most times has to drive straight, \textit{no action} state even dominates in dataset 3.

The important condition in a classification task is to have balanced classes.
Unfortunately in our case, this balance is not achieved. With this limitation, the
evaluation is carried forward.

\subsection{Observations}
\begin{enumerate}
    \item Steering angle uses tanh activation and MSE loss functions
    \item Classify acceleration prediction as classification task which means softmax as
        activation.
    \item Since acceleration carries three states, categorical crossentropy as loss
        function.
    \item Dataset 3 has more of acceleration and braking states than dataset 1. So dataset
        3 is preferred.
\end{enumerate}
\section{Predicting acceleration - categorical crossentropy}
\label{chapter5sec:cce}
Now that the basic criteria for training is fixed such as which dataset, activation, and
loss functions, we can move ahead and optimise the predicted classes by tuning the
neutral network.

\subsection*{LSTM vs Non-LSTM}
Before going into tuning the neural network, it is necessary to tell that acceleration
prediction needs temporal information; meaning decision to drive slower or faster depends
on the previous, historical frames. LSTM is used for this purpose. When non-LSTM model is used
to predict acceleration, it only predicts for the current frame(doesn't provide past
frames information) which often results in vehicle being stationary.
\begin{figure}[!ht]
    \centering
    \def\svgwidth{0.8\textwidth}
    \input{figures/inkscape/lstmvsnolstm.pdf_tex}
    \caption{Datasets 3 - No LSTM vs LSTM comparison}
    \label{fig:ds3nolstmvslstm}
\end{figure}
For our setup, we choose a $timestep = 15$. That means acceleration of current time frame
is predicted using previous 14 time frames.
\subsubsection*{Determining the optimal LSTM output units}
In Keras, the LSTM units refer to the dimension of hidden state vector \textit{h} that is the state output from RNN cell.
The table \ref{table:unitsvstime}, compares different unit values and the number of
trainable parameters(weight that can be trained during backpropagation) at this LSTM
layer.
In our case, it means that for a time series of 15, there will be 15 \textit{cell states},
15 \textit{hidden states}, and 15 \textit{outputs} each of vector size defined by the
units in the table such as 20, 60 or 100.

Upon evaluation with these different units, 100 output units though has the highest
trainable parameters for this layer alone, retains more information needed for training
the model.  Hence, a LSTM unit of 100 is chosen.
\begin{table}[h]
    \centering
\begin{tabular}{ccc}
    \toprule
    LSTM Output Units & Trainable Parameters(ca.) & Processing time needed \\\midrule
    20 & 20000 & 1hr 44m  \\
    60 & 61000 & 1hr 42m \\
    100 & 434000  & 1hr 40m \\\bottomrule
\end{tabular}
\caption{LSTM Output Units vs Trainable Parameters vs Training time}
\label{table:unitsvstime}
\end{table}
\newpage
\subsection{Basic Model}
\begin{wrapfigure}{l}{0.4\textwidth}
	\centering
    \def\svgwidth{0.4\textwidth}
    \input{figures/inkscape/steeringbasicmodel.pdf_tex} %use full path to know the location of pdftex
    \caption{Basic model}
    \label{fig:steeringbasicmodel}
\end{wrapfigure}

For training, a model as shown in figure \ref{fig:steeringbasicmodel}, is designed and its
result is seen in figure \ref{fig:ds3categoricalcrossentropybasic}. Interestingly, the
training loss curve \textit{follows} the classification loss as it dominates the model. Steering
loss however, after epoch 32 starts to increase. Sure enough, upon evaluation,
the steering was all over the place and acceleration was not stable at all, resulting in
many collisions as shown in table \ref{table:softmaxandcce} (dataset 3 column).

The cause for this behaviour is investigated and it is found that different losses have
different magnitudes. By forcing the neural network to learn/train both classification and
regression losses from a same dense layer causes instability in learning.

\begin{figure}[t]
	\centering
    \def\svgwidth{0.8\textwidth}
    \input{figures/inkscape/categoricalcrossds3.pdf_tex} %use full path to know the location of pdftex
    \caption{Basic model}
    \label{fig:ds3categoricalcrossentropybasic}
    \vspace*{-0.30in}
\end{figure}
\vspace{-.2in}
\subsection{Splitting at the dense layers}
To alleviate some of the burden the second dense layer(dense 2) is split into two separate dense
layers; one for classification outputs and other for steering as show in figure
\ref{fig:steeringdensesplit}. The result \ref{fig:ds3categoricalcrossentropydense}, stops
the strange steering loss increase. Upon evaluation, this model shows better steering
control but still the acceleration is not stable or consistent as shown in table
\ref{table:ccedense}.
\begin{figure}[!ht]
	\centering
    \def\svgwidth{0.5\textwidth}
    \input{figures/inkscape/steeringdensesplit.pdf_tex} %use full path to know the location of pdftex
    \caption{Split at the second dense layer}
    \label{fig:steeringdensesplit}
\end{figure}

\begin{figure}[!ht]
	\centering
    \def\svgwidth{0.8\textwidth}
    \input{figures/inkscape/categoricalcrossds3dense.pdf_tex} %use full path to know the location of pdftex
    \caption{Separate dense layers for classification and steering}
    \label{fig:ds3categoricalcrossentropydense}
\end{figure}

\begin{table}[h]
    \centering
\begin{tabular}{lc}
    \toprule
    Criteria(Softmax/Categorical crossentropy)  & Dataset 3 \\\midrule
    Lane keeping/Drive straight  & Yes  \\
    Gradual acceleration increase  & Yes\\
    Smooth braking behaviour observed & Yes \\
    Smooth steering control at high speed(10m/s) & No \\
    Smooth steering control at turnings & No\\
    Avoids colliding into static objects & No \\
    Detects vehicles as dynamic objects & Yes \\
    Navigates traffic smoothly & No\\
    Doesn't stop at random places & No \\\bottomrule
\end{tabular}
\caption{Separate dense layers - How the model evaluates to different criteria}
\label{table:ccedense}
\end{table}
\newpage
\subsection{Splitting at the LSTM layers}
Continuing the theme of tuning the network, the model is split further at LSTM layer as shown in figure
\ref{fig:steeringlstmsplit}. The main aim here is to see if steering control improves and
is stable for considerable acceleration prediction. From figure
\ref{fig:ds3categoricalcrossentropylstm}, the steering loss gets a marginal gain. Still at
evaluation, the trained models stops at random places, and steering control is not stable at
higher acceleration predicted values. Hence the predicted acceleration value is reduced by
50-70\% and fed to the controller. Sure enough the vehicle exhibits stable movements as
seen from table \ref{table:cceLSTM}.

\begin{figure}[!ht]
	\centering
    \def\svgwidth{0.5\textwidth}
    \input{figures/inkscape/steeringlstmsplit.pdf_tex} %use full path to know the location of pdftex
    \caption{Split at the LSTM layer}
    \label{fig:steeringlstmsplit}
\end{figure}

\begin{figure}[!ht]
	\centering
    \def\svgwidth{0.8\textwidth}
    \input{figures/inkscape/categoricalcrossds3lstm.pdf_tex} %use full path to know the location of pdftex
    \caption{Separate LSTM layers for classification and steering}
    \label{fig:ds3categoricalcrossentropylstm}
\end{figure}
\begin{table}[!ht]
    \centering
\begin{tabular}{lc}
    \toprule
    Criteria(Softmax/Categorical crossentropy)  & Dataset 3 \\\midrule
    Lane keeping/Drive straight  & Yes  \\
    Gradual acceleration increase  & Yes\\
    Smooth braking behaviour observed & Yes \\
    Smooth steering control at high speed(10m/s) & Yes \\
    Smooth steering control at turnings & No\\
    Avoids colliding with static objects & No \\
    Detects vehicles as dynamic objects & Yes \\
    Navigates traffic smoothly & Yes\\
    Doesn't stop at random places(negative case) & Yes \\
    Smooth evaluation experience & No \\\bottomrule

\end{tabular}
\caption{Split at the LSTM layer - How the model evaluates to different criteria}
\label{table:cceLSTM}
\end{table}

\subsection{Using two different NN for acceleration and
Steering}
It can be deduced that optimised weights play an important role on how it influences
steering and acceleration prediction. The model is now split as two different neural
networks(NN) as seen in figure \ref{fig:steeringnnsplit}. Though the result
\ref{fig:ds3categoricalcrossentropy2nn} looks similar to
\ref{fig:ds3categoricalcrossentropylstm}, the model predicts stable, consistent
acceleration values.

From table \ref{table:cce2NN}, it even exhibits occasional turning behaviours at junctions. When it
is exposed to traffic, the model does well to navigate, brake, and accelerate.
\begin{figure}[!ht]
	\centering
    \def\svgwidth{0.5\textwidth}
    \input{figures/inkscape/steeringNNsplit.pdf_tex} %use full path to know the location of pdftex
    \caption{Separate NN training model}
    \label{fig:steeringnnsplit}
\end{figure}

\begin{figure}[!ht]
	\centering
    \def\svgwidth{0.8\textwidth}
    \input{figures/inkscape/categoricalcrossds32nn.pdf_tex} %use full path to know the location of pdftex
    \caption{Separate neural network for Classification and Steering}
    \label{fig:ds3categoricalcrossentropy2nn}
\end{figure}
\begin{table}[!ht]
    \centering
\begin{tabular}{lc}
    \toprule
    Criteria(Softmax/Categorical crossentropy)  & Dataset 3 \\\midrule
    Lane keeping/Drive straight  & Yes  \\
    Gradual acceleration increase  & Yes\\
    Smooth braking behaviour observed & Yes \\
    Smooth steering control at high speed(10m/s) & Yes \\
    Smooth steering control at turnings & No\\
    Avoids colliding with static objects & Yes \\
    Detects vehicles as dynamic objects & Yes \\
    Navigates traffic smoothly & Yes\\
    Doesn't stop at random places(negative case) & Yes \\
    Smooth evaluation experience & Yes \\\bottomrule
\end{tabular}
\caption{Separate neural network for classification and steering outputs - How the model evaluates to different criteria}
\label{table:cce2NN}
\end{table}

A quick overview of steering losses across different NN changes is shown in figure
 \ref{fig:ds3categoricalcrossentropysteeringcompare}.
 \begin{figure}[!ht]
	\centering
    \def\svgwidth{\textwidth}
    \input{figures/inkscape/categoricalcrossds3steeringCompare.pdf_tex} %use full path to know the location of pdftex
    \caption{Steering command loss comparison}
    \label{fig:ds3categoricalcrossentropysteeringcompare}
\end{figure}
\newpage \vfill
\subsection{Observations}
\begin{enumerate}
    \item Tuning the neural network albeit only the fully connected layers, results in
        optimised prediction of steering control corresponding to the classification
        outputs.
    \item The car exhibits random, unknown stops at random places. The actual reason
        behind it is unknown but it is suspected that since the dataset has imbalanced
        classes, it contributes to this random decisions.
    \item Separating into two NNs allows better steering control at a higher speed.
    \item Sunlight and shadows still play a major role. They do some random, strange
        things to models that eventually lead to crashes out-of-nowhere. It could be
        deduced that some buildings' shadows could be considered as static or dynamic
        objects.
\end{enumerate}
\section{Velocity}
Velocity is a scalar value, labelled output. It is considered as an \textit{auxiliary
task}. An auxiliary task usually consists of estimating quantities that are relevant to
solving main supervised learning problem. That means that velocity is predicted as an
auxiliary task using existing CNN-LSTM-Dense architectures without affecting the major
tasks i.e., predicting acceleration and steering.

The images are fed into the models shown in figure \ref{fig:velocitycompareNN} and results are
compared as how predicting velocity affects acceleration and steering.
\begin{figure}[!ht]
    \def\svgwidth{1.15\textwidth}
    \input{figures/inkscape/velocitycompareNN.pdf_tex} %use full path to know the location of pdftex
    \caption{Different architectures used while predicting velocity}
    \label{fig:velocitycompareNN}
\end{figure}

From the figure \ref{fig:velocitycompareloss1}, looking at the loss-epoch graphs of model
\textit{a}, \textit{b}, \textit{c}, the validation losses follow velocity's validation loss.
When compared to classification and steering loss, this loss is too high. Sure enough
while evaluating steering and acceleration are worse. Since velocity is an auxiliary task,
there is a need to rethink how cost function is calculated.
\begin{figure}[!ht]
	\centering
    \def\svgwidth{\textwidth}
    \input{figures/inkscape/velocitycomparelosses5.pdf_tex} %use full path to know the location of pdftex
    \caption{Comparison of losses for NN architectures shown in figure \ref{fig:velocitycompareNN}}
    \label{fig:velocitycompareloss1}
\end{figure}

\subsection{Weighted loss function}
Since velocity is taking control of the neural network to provide feature extraction and
decision making for its prediction, both acceleration and steering suffer bad
consequences. In order to avoid this, weighted cost function is introduced to the three
outputs. As velocity is an auxiliary task, it is suppressed more than others. From figures
\ref{fig:velocitycompareNN} and \ref{fig:velocitycompareloss1}, model \textit{a} gives
nearly optimum losses. So that model is chosen to carry out this weighted cost function
experiment.

The model is tweaked only to include custom, weighted cost function. The trained model
exhibits now losses similar to classification losses than velocity(as seen in figure
\ref{fig:velocitycompareloss1}, \textit{weighted} graph). Indeed during
evaluation, acceleration and steering both get preference and control than velocity.
Hence it is possible to include auxiliary tasks to normal NNs without compromising the
actual functionality of it.

\section{Convolution layers manipulation}
The fully connected/dense layers are tweaked to various designs as shown in
figures \ref{fig:steeringbasicmodel}, \ref{fig:steeringdensesplit},
\ref{fig:steeringlstmsplit}, \ref{fig:steeringnnsplit} and having convolutional layers as
constant. Some interesting possibilities and observations are made possible. As a
consequence, the convolutional layers are changed keeping dense layers as constant.
We are going to make prediction of velocity also. Hence
\ref{fig:velocitycompareNN}(\textit{a}
model) does
relatively well in both setup, convolutional layer experiments are done using this model.

\subsection{Adjusting the width of the convolutional layers}
\subsubsection*{Changing the feature maps channel depth}}
The convolutional layers consists of feature maps channels, kernel filter which convolves
on the input using a specified stride. In our case, the last convolutional layer's feature
map channel's depth is increased from 64 to 80. This after \textit{flatten} layer
increases the trainable parameters. This allows more features to carried into the fully connected layer.
\begin{figure}[!ht]
	\centering
    \def\svgwidth{\textwidth}
    \input{figures/inkscape/velocitysplitconvlayerschange6.pdf_tex} %use full path to know the location of pdftex
    \caption{Convolutional layers width changes - Increasing feature maps channel depth}
    \label{fig:convlayerschange1}
\end{figure}
\subsubsection*{Changing the stride}
Stride is a component in CNN tuned for compressing the images data. This parameter
specifies the movement step of the kernel/filter. In our case, the stride of the 5th
convolutional layer is decreased from (2,2) to (1,1). Hence ensures the information
tensors are not reduced by half and increasing the trainable parameters of the features.

\subsection{Depth of the Convolutional layers}
\subsubsection*{Increase the convolutional layers to eleven}
\begin{figure}[!ht]
	\centering
    \def\svgwidth{1.15\textwidth}
    \input{figures/inkscape/velocitysplitconvlayerschange5.pdf_tex} %use full path to know the location of pdftex
    \caption{Convolutional layers depth changes - Increasing the number of CNN layers}
    \label{fig:convlayerschange3}
\end{figure}
\subsubsection*{Increase the convolutional layers to eight}

\iffalse
\begin{figure}[!ht]
	\centering
    \def\svgwidth{\textwidth}
    \input{figures/inkscape/carsensors.pdf_tex} %use full path to know the location of pdftex
    \caption{Sensor Constellation}
    \label{fig:simplesensorconstellation}
\end{figure}
\section{Testbed setup}

\begin{enumerate}
    \item dataset constant - Only dry day data?
        or everything?
    \item CNN parameters variable.
    \item epochs, learning rate, optimizer, loss function constant
    \item activation function constant or variable?
    \item for LSTM - timesteps value?
    \item graph - training, val loss vs epochs?
    \item graph - loss vs learning rate?
    \item graph - timesteps vs loss?
    \item graph - evaluation performance comparison?
    \item graph - Accel, brake, noaction predicted vs ?
    \item graph - brake, steering predicted vs ?
    \item graph - accel, brake, steering predicted vs ?
    \item graph - accel,brake, steering, distance(radar) predicted vs ?
    \item graph - with seg camera vs without?
    \item graph - with radar vs without?
    \item graph - imbalanced vs balanced Cross entropy?

\end{enumerate}
\fi
